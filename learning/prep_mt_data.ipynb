{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODOS\n",
      "# - more tests and sanity checks\n",
      "# - add cross validation harness\n",
      "# - add random instance selection\n",
      "# - load serialized indices, run random indexing, and print scores into:\n",
      "# en-es.sim_scores\n",
      "\n",
      "# TODO: this doesn't work inside the ipython notebook for some reason\n",
      "# %run /home/chris/projects/random_indexing/python/wmt2014/quality_estimation/test_random_indexing.py\n",
      "\n",
      "# split that file into 10 parts (randomly) and do cross-validation\n",
      "\n",
      "# SETUP PARAMS\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sanity check: are our features any good? - compare high-scoring pairs to their QE scores\n",
      "# 10.3.14 - Answer: currently no :-(\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import unittest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODOS\n",
      "# - add cross validation harness\n",
      "# - add random instance selection\n",
      "# - load serialized indices\n",
      "import re\n",
      "\n",
      "# run the indexing and serialization code here\n",
      "# Working - split the data for cross-validation\n",
      "similarity_data_path = '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/output/'\n",
      "quest_data_path = '/home/chris/programs/quest/learning/data/features/wmt2014_qe_experiments/'\n",
      "\n",
      "# semantic_scores = open(similarity_data_path + 'en-es.sim_scores', 'r').readlines()\n",
      "# print(len(semantic_scores))\n",
      "# human_scores = open(quest_data_path + 'train.effort', 'r').read().splitlines()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# open  the new features\n",
      "# rand_train = open(similarity_data_path + 'en-es.sim_scores.train', 'r').read().splitlines()\n",
      "# rand_test = open(similarity_data_path + 'en-es.sim_scores.test', 'r').read().splitlines()\n",
      "semantic_scores = open(similarity_data_path + 'en-es.sim_scores', 'r').read().splitlines()\n",
      "rand_train=semantic_scores[:3000]\n",
      "rand_test =semantic_scores[3000:]\n",
      "# open  the existing features\n",
      "# these are features learned and output by the quest framework\n",
      "quest_train = open(quest_data_path + 'train.15.en-es.tsv', 'r').read().splitlines()\n",
      "quest_test = open(quest_data_path + 'test.15.en-es.tsv', 'r').read().splitlines()\n",
      "\n",
      "train_scores = open(quest_data_path + 'train.effort', 'r').read().splitlines()\n",
      "test_scores = open(quest_data_path + 'test.effort', 'r').read().splitlines()\n",
      "\n",
      "# PREP THE TEST DATA\n",
      "new_train = [q + '\\t' + r for q,r in zip(quest_train, rand_train)]\n",
      "new_test = [q + '\\t' + r for q,r in zip(quest_test, rand_test)]\n",
      "# print (new_train[5:])\n",
      "# print (new_test[5:])\n",
      "# without the extra features - Quest file only\n",
      "# new_train = quest_train\n",
      "# new_test = quest_test\n",
      "\n",
      "# JUST the extra feature\n",
      "new_train = rand_train\n",
      "new_test = rand_test\n",
      "\n",
      "train_len = len(new_train)\n",
      "test_len = len(new_test)\n",
      "\n",
      "# sanity check - random vals between 0-1\n",
      "#new_train = [np.random.random() for l in range(train_len)]\n",
      "#new_test = [np.random.random() for l in range(test_len)]\n",
      "\n",
      "print (\"rand_train length: %i rand_test length: %i\" % (len(rand_train), len(rand_test)))\n",
      "print (\"quest_train length: %i quest_test length: %i\" % (len(quest_train), len(quest_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rand_train length: 3000 rand_test length: 816\n",
        "quest_train length: 3000 quest_test length: 816\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_dir = '/home/chris/projects/quest-new/learning/data/features/ems_output/'\n",
      "\n",
      "# use pandas to enable super powers\n",
      "import pandas as pd\n",
      "\n",
      "data_instances = pd.io.parsers.read_table('/home/chris/projects/quest-new/output/wmt2014/source.en.tok_to_target.es.tok.out')\n",
      "print (data_instances.shape)\n",
      "data_instances\n",
      "\n",
      "# shuffle data randomly \n",
      "#rows = np.random.choice(df.index.values, 10)\n",
      "#sampled_df = df.ix[rows] \n",
      "#df_90 = df.drop(rows)\n",
      "\n",
      "# Working - get quest to output the feature index\n",
      "# Update -- feature indexing works, but quest prints with a trailing whitespace, so the index loading is still messed up"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(5, 15)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>1001</th>\n",
        "      <th>1002</th>\n",
        "      <th>1006</th>\n",
        "      <th>1015</th>\n",
        "      <th>1022</th>\n",
        "      <th>1036</th>\n",
        "      <th>1046</th>\n",
        "      <th>1049</th>\n",
        "      <th>1050</th>\n",
        "      <th>1053</th>\n",
        "      <th>1054</th>\n",
        "      <th>1057</th>\n",
        "      <th>1058</th>\n",
        "      <th>1074</th>\n",
        "      <th>1075</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td> 12</td>\n",
        "      <td> 12</td>\n",
        "      <td> 3.833333</td>\n",
        "      <td> 1.090909</td>\n",
        "      <td> 185.16667</td>\n",
        "      <td> 0.007165</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.750000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.454545</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.300000</td>\n",
        "      <td> 0.727273</td>\n",
        "      <td> 2</td>\n",
        "      <td> 4</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 24</td>\n",
        "      <td> 25</td>\n",
        "      <td> 3.875000</td>\n",
        "      <td> 1.315789</td>\n",
        "      <td> 163.00000</td>\n",
        "      <td> 0.009742</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.916667</td>\n",
        "      <td> 0.043478</td>\n",
        "      <td> 0.826087</td>\n",
        "      <td> 0.090909</td>\n",
        "      <td> 0.590909</td>\n",
        "      <td> 0.950000</td>\n",
        "      <td> 3</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td> 20</td>\n",
        "      <td> 20</td>\n",
        "      <td> 4.650000</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 221.20000</td>\n",
        "      <td> 0.063421</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.950000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.684211</td>\n",
        "      <td> 0.055556</td>\n",
        "      <td> 0.388889</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 2</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>  8</td>\n",
        "      <td>  8</td>\n",
        "      <td> 4.125000</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 149.75000</td>\n",
        "      <td> 0.143632</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.750000</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.428571</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.166667</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td> 15</td>\n",
        "      <td> 14</td>\n",
        "      <td> 3.133333</td>\n",
        "      <td> 1.166667</td>\n",
        "      <td> 274.00000</td>\n",
        "      <td> 0.090408</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0.933333</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.571429</td>\n",
        "      <td> 0.000000</td>\n",
        "      <td> 0.384615</td>\n",
        "      <td> 1.000000</td>\n",
        "      <td> 2</td>\n",
        "      <td> 0</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 15 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 27,
       "text": [
        "   1001  1002      1006      1015       1022      1036  1046      1049  \\\n",
        "0    12    12  3.833333  1.090909  185.16667  0.007165     0  0.750000   \n",
        "1    24    25  3.875000  1.315789  163.00000  0.009742     0  0.916667   \n",
        "2    20    20  4.650000  1.000000  221.20000  0.063421     0  0.950000   \n",
        "3     8     8  4.125000  1.000000  149.75000  0.143632     0  0.750000   \n",
        "4    15    14  3.133333  1.166667  274.00000  0.090408     0  0.933333   \n",
        "\n",
        "       1050      1053      1054      1057      1058  1074  1075  \n",
        "0  0.000000  0.454545  0.000000  0.300000  0.727273     2     4  \n",
        "1  0.043478  0.826087  0.090909  0.590909  0.950000     3     2  \n",
        "2  0.000000  0.684211  0.055556  0.388889  1.000000     0     2  \n",
        "3  0.000000  0.428571  0.000000  0.166667  1.000000     0     0  \n",
        "4  0.000000  0.571429  0.000000  0.384615  1.000000     2     0  \n",
        "\n",
        "[5 rows x 15 columns]"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now get the results of ML with these features\n",
      "# TODO: store the results in csv with some metadata about the experimental params\n",
      "# ml_directory = '/home/chris/programs/quest/learning/\n",
      "# python src/learn_model.py config/svr.yaml\n",
      "%run src/learn_model.py config/svr.cfg\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Opening input files ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Scaling datasets...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Tuning hyper-parameters for mae\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing a loss function is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''. \n",
        "  self.loss_func, self.score_func, self.scoring)\n",
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.0s finished\n",
        "INFO:root:Best parameters set found on development set:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:{'epsilon': 0.10000000000000001, 'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Tuning hyper-parameters for rmse\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "kernel ['rbf']\n",
        "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
        "Fitting 3 folds for each of 8 candidates, totalling 24 fits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing a loss function is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''. \n",
        "  self.loss_func, self.score_func, self.scoring)\n",
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.0s finished\n",
        "INFO:root:Best parameters set found on development set:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:{'epsilon': 0.10000000000000001, 'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running learning algorithm SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.01,\n",
        "  kernel=rbf, max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting unseen data using the trained model...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Evaluating prediction on the test set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:mae = 0.46500703813\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:rmse = 0.659793355871\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# output files\n",
      "training = output_dir + 'training-features.out'\n",
      "test = output_dir + 'test-features.out'\n",
      "# this cell formats and prints the training features\n",
      "with open(training,'w') as f:\n",
      "    for row in new_train:\n",
      "        print (row, file=f)\n",
      "        \n",
      "with open(test,'w') as f:\n",
      "    for row in new_test:\n",
      "        print (row, file=f)\n",
      "\n",
      "\n",
      "# TODO: try other classifiers -- get some better intuition about the performance\n",
      "# LR, NB to start\n",
      "# Neural network, etc..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "u'/home/chris/programs/quest/learning'"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run 1 with extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412518890672\n",
      "# INFO:root:rmse = 0.602574628609\n",
      "\n",
      "# run 2 WITHOUT extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412413880436\n",
      "# INFO:root:rmse = 0.602584789385\n",
      "\n",
      "# run 3 JUST extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465217126314\n",
      "# INFO:root:rmse = 0.659930041776\n",
      "\n",
      "# run 4 sanity check - random features:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465236937727\n",
      "# INFO:root:rmse = 0.659939032088\n",
      "\n",
      "# random results confirmed:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465119763497\n",
      "# INFO:root:rmse = 0.659865420079\n",
      "\n",
      "# COMING BACK - after zeroing the corpus indicies for cells which are only 1 or -1\n",
      "# finished indexing tokens...\n",
      "# similarity between vecs for: oro and gold is: 0.504181\n",
      "# similarity between vecs for: oro and covet is: 0.965443\n",
      "# before zeroing: \n",
      "# INDEX: 4798 - Source and target sentence similarity after random indexing: 0.674727\n",
      "# INDEX: 4798 - Source similarity with a random target (index 4155): 0.699771\n",
      "# after zeroing: \n",
      "# INDEX: 4798 - Source and target sentence similarity after random indexing: 0.674727\n",
      "# INDEX: 4798 - Source similarity with a random target (index 14408): 0.883923\n",
      "\n",
      "# with the new (index-zeroed) feature\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412617446921\n",
      "# INFO:root:rmse = 0.602652127017\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}