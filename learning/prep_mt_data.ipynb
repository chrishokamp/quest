{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# get the pearson correlation between the similarity scores and the quality scores\n",
      "\n",
      "\n",
      "# train_scores = open('/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/perceived_PE_effort/task1-1_en-es_training/en-es_scores', 'r').readlines()\n",
      "train_scores = open('/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/perceived_PE_effort/task1-1_en-es_training/en-es_scores', 'r').readlines()[:1000]\n",
      "similarity_scores = open('/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/similarity-scores.out','r').readlines()[:1000]\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "\n",
      "real_scores = np.nan_to_num(np.array(train_scores).astype('float32'))\n",
      "#print np.isnan(real_scores)\n",
      "sim_scores = np.nan_to_num(np.array(similarity_scores).astype('float32'))\n",
      "coor = sp.stats.pearsonr(real_scores, sim_scores)\n",
      "#print(coor)\n",
      "coor\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "(0.0047633257, 0.8804158737273291)"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# pearson\n",
      "# scores DO NOT correlate with quality at all\n",
      "# 1- (0.0025929597, 0.87278283102266641)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# TODOS\n",
      "# - load serialized indices, run random indexing, and print scores into:\n",
      "# en-es.sim_scores\n",
      "\n",
      "# TODO: this doesn't work inside the ipython notebook for some reason\n",
      "# %run /home/chris/projects/random_indexing/python/wmt2014/quality_estimation/test_random_indexing.py\n",
      "\n",
      "# split that file into 10 parts (randomly) and do cross-validation\n",
      "\n",
      "# SETUP PARAMS\n",
      "\n",
      "# wmt12 data\n",
      "wmt_effort_scores = '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/wmt_2012_data/QualityEstimation/training_set_annotations/target_system.effort'\n",
      "wmt_baseline_output= '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/wmt_2012_data/QualityEstimation/baseline/output/source.eng.tok_to_target_system.spa.tok.out'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sanity check: are our features any good? - compare high-scoring pairs to their QE scores\n",
      "# 10.3.14 - Answer: currently no :-(\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import print_function\n",
      "import unittest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODOS\n",
      "# - add cross validation harness\n",
      "# - add random instance selection\n",
      "# - load serialized indices\n",
      "import re\n",
      "\n",
      "# run the indexing and serialization code here\n",
      "# Working - split the data for cross-validation\n",
      "similarity_data_path = '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/output/'\n",
      "quest_data_path = '/home/chris/projects/quest-new/learning/data/features/wmt2014_qe_experiments/'\n",
      "\n",
      "# semantic_scores = open(similarity_data_path + 'en-es.sim_scores', 'r').readlines()\n",
      "# print(len(semantic_scores))\n",
      "# human_scores = open(quest_data_path + 'train.effort', 'r').read().splitlines()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# open  the new features\n",
      "semantic_scores = open(similarity_data_path + 'en-es.sim_scores', 'r').read().splitlines()\n",
      "rand_train=semantic_scores[:3000]\n",
      "rand_test =semantic_scores[3000:]\n",
      "# open  the existing features\n",
      "# these are features learned and output by the quest framework\n",
      "quest_train = open(quest_data_path + 'train.15.en-es.tsv', 'r').read().splitlines()\n",
      "quest_test = open(quest_data_path + 'test.15.en-es.tsv', 'r').read().splitlines()\n",
      "\n",
      "train_scores = open(quest_data_path + 'train.effort', 'r').read().splitlines()\n",
      "test_scores = open(quest_data_path + 'test.effort', 'r').read().splitlines()\n",
      "\n",
      "# PREP THE TEST DATA\n",
      "new_train = [q + '\\t' + r for q,r in zip(quest_train, rand_train)]\n",
      "new_test = [q + '\\t' + r for q,r in zip(quest_test, rand_test)]\n",
      "# print (new_train[5:])\n",
      "# print (new_test[5:])\n",
      "# without the extra features - Quest file only\n",
      "# new_train = quest_train\n",
      "# new_test = quest_test\n",
      "\n",
      "# JUST the extra feature\n",
      "new_train = rand_train\n",
      "new_test = rand_test\n",
      "\n",
      "train_len = len(new_train)\n",
      "test_len = len(new_test)\n",
      "\n",
      "# sanity check - random vals between 0-1\n",
      "#new_train = [np.random.random() for l in range(train_len)]\n",
      "#new_test = [np.random.random() for l in range(test_len)]\n",
      "\n",
      "print (\"rand_train length: %i rand_test length: %i\" % (len(rand_train), len(rand_test)))\n",
      "print (\"quest_train length: %i quest_test length: %i\" % (len(quest_train), len(quest_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rand_train length: 3000 rand_test length: 816\n",
        "quest_train length: 3000 quest_test length: 816\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_dir = '/home/chris/projects/quest-new/learning/data/features/ems_output/'\n",
      "\n",
      "# use pandas to enable super powers\n",
      "import math as math\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "# TODO: use nose for testing\n",
      "\n",
      "#data_instances = pd.io.parsers.read_table('/home/chris/projects/quest-new/output/wmt2014/source.en.tok_to_target.es.tok.out')\n",
      "\n",
      "wmt_baseline_output= '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/wmt_2012_data/QualityEstimation/baseline/output/source.eng.tok_to_target_system.spa.tok.out'\n",
      "data_instances = pd.io.parsers.read_table(wmt_baseline_output)\n",
      "# print(data_instances)\n",
      "print(data_instances.shape)\n",
      "# Working - add the y values (training scores) as the final column\n",
      "\n",
      "# TODO: add hooks to retrain quest here\n",
      "# cp ~/projects/random_indexing/python/wmt2014/quality_estimation/data/perceived_PE_effort/task1-1_en-es_training/en-es_source.train source.en{^\n",
      "\n",
      "# SCORES\n",
      "# WMT 2012 data\n",
      "#train_scores = pd.io.parsers.read_table('/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/wmt_2012_data/QualityEstimation/training_set_annotations/target_system.effort')\n",
      "\n",
      "# WMT 2014 data \n",
      "train_scores = pd.io.parsers.read_table('/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/perceived_PE_effort/task1-1_en-es_training/en-es_score.train')\n",
      "print(train_scores.shape)\n",
      "\n",
      "data_instances['train_scores'] = train_scores\n",
      "data_instances = data_instances.astype('float64', copy=True)\n",
      "data_instances.replace(np.inf, 0.0)\n",
      "\n",
      "print (data_instances.shape)\n",
      "data_instances.dropna(0)\n",
      "print (data_instances.shape)\n",
      "\n",
      "#print (data_instances.shape)\n",
      "\n",
      "# shuffle data randomly \n",
      "# 10% test data \n",
      "def split_data(complete_frame, test_percent_split):\n",
      "    x_size = complete_frame.shape[0]\n",
      "    test_data_size = math.floor(x_size / test_percent_split)\n",
      "\n",
      "    test_rows = np.random.choice(complete_frame.index.values, test_data_size)\n",
      "\n",
      "    test_data = complete_frame.ix[test_rows]  \n",
      "    train_data = complete_frame.drop(test_rows)\n",
      "\n",
      "    return { 'train': train_data, 'test': test_data }\n",
      "\n",
      "train_test = split_data(data_instances, 10)\n",
      "#print ('train shape: %s' % str(train_test['train'].shape))\n",
      "#print ('test shape: %s' % str(train_test['test'].shape))\n",
      "# train_test\n",
      "\n",
      "# call the scikit-learn code here\n",
      "\n",
      "\n",
      "#print(train_test['train']['train_scores'])\n",
      "\n",
      "#data_instances\n",
      "# Working - get quest to output the feature index descriptions \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3816, 17)\n",
        "(3816, 1)\n",
        "(3816, 18)\n",
        "(3816, 18)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:45: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def set_learning_method(config, X_train, y_train):\n",
      "    \"\"\"\n",
      "    Instantiates the sklearn's class corresponding to the value set in the \n",
      "    configuration file for running the learning method.\n",
      "    \n",
      "    @param config: configuration object\n",
      "    @return: an estimator with fit() and predict() methods\n",
      "    \"\"\"\n",
      "    estimator = None\n",
      "    \n",
      "    learning_cfg = config.get(\"learning\", None)\n",
      "    if learning_cfg:\n",
      "        p = learning_cfg.get(\"parameters\", None)\n",
      "        o = learning_cfg.get(\"optimize\", None)\n",
      "        scorers = \\\n",
      "        set_scorer_functions(learning_cfg.get(\"scorer\", ['mae', 'rmse']))\n",
      "        \n",
      "        method_name = learning_cfg.get(\"method\", None)\n",
      "        if method_name == \"SVR\":\n",
      "            if o:\n",
      "                tune_params = set_optimization_params(o)\n",
      "                estimator = optimize_model(SVR(), X_train, y_train, \n",
      "                                          tune_params, \n",
      "                                          scorers, \n",
      "                                          o.get(\"cv\", 5),\n",
      "                                          o.get(\"verbose\", True),\n",
      "                                          o.get(\"n_jobs\", 1))\n",
      "                \n",
      "            elif p:\n",
      "                estimator = SVR(C=p.get(\"C\", 10),\n",
      "                                epsilon=p.get('epsilon', 0.01),\n",
      "                                kernel=p.get('kernel', 'rbf'),\n",
      "                                degree=p.get('degree', 3),\n",
      "                                gamma=p.get('gamma', 0.0034),\n",
      "                                tol=p.get('tol', 1e-3),\n",
      "                                verbose=False)\n",
      "            else:\n",
      "                estimator = SVR()\n",
      "        \n",
      "        elif method_name == \"SVC\":\n",
      "            if o:\n",
      "                tune_params = set_optimization_params(o)\n",
      "                estimator = optimize_model(SVC(), X_train, y_train,\n",
      "                                           tune_params,\n",
      "                                           scorers,\n",
      "                                           o.get('cv', 5),\n",
      "                                           o.get('verbose', True),\n",
      "                                           o.get('n_jobs', 1))\n",
      "                \n",
      "            elif p:\n",
      "                estimator = SVC(C=p.get('C', 1.0),\n",
      "                                kernel=p.get('kernel', 'rbf'), \n",
      "                                degree=p.get('degree', 3),\n",
      "                                gamma=p.get('gamma', 0.0),\n",
      "                                coef0=p.get('coef0', 0.0),\n",
      "                                tol=p.get('tol', 1e-3),\n",
      "                                verbose=p.get('verbose', False))\n",
      "            else:\n",
      "                estimator = SVC()\n",
      "                    \n",
      "        elif method_name == \"LassoCV\":\n",
      "            if p:\n",
      "                estimator = LassoCV(eps=p.get('eps', 1e-3),\n",
      "                                    n_alphas=p.get('n_alphas', 100),\n",
      "                                    normalize=p.get('normalize', False),\n",
      "                                    precompute=p.get('precompute', 'auto'),\n",
      "                                    max_iter=p.get('max_iter', 1000),\n",
      "                                    tol=p.get('tol', 1e-4),\n",
      "                                    cv=p.get('cv', 10),\n",
      "                                    verbose=False)\n",
      "            else:\n",
      "                estimator = LassoCV()\n",
      "        \n",
      "        elif method_name == \"LassoLars\":\n",
      "            if o:\n",
      "                tune_params = set_optimization_params(o)\n",
      "                estimator = optimize_model(LassoLars(), X_train, y_train, \n",
      "                                          tune_params,\n",
      "                                          scorers,\n",
      "                                          o.get(\"cv\", 5),\n",
      "                                          o.get(\"verbose\", True),\n",
      "                                          o.get(\"n_jobs\", 1))\n",
      "                \n",
      "            if p:\n",
      "                estimator = LassoLars(alpha=p.get('alpha', 1.0),\n",
      "                                      fit_intercept=p.get('fit_intercept', True),\n",
      "                                      verbose=p.get('verbose', False),\n",
      "                                      normalize=p.get('normalize', True),\n",
      "                                      max_iter=p.get('max_iter', 500),\n",
      "                                      fit_path=p.get('fit_path', True))\n",
      "            else:\n",
      "                estimator = LassoLars()\n",
      "        \n",
      "        elif method_name == \"LassoLarsCV\":\n",
      "            if p:\n",
      "                estimator = LassoLarsCV(max_iter=p.get('max_iter', 500),\n",
      "                                        normalize=p.get('normalize', True),\n",
      "                                        max_n_alphas=p.get('max_n_alphas', 1000),\n",
      "                                        n_jobs=p.get('n_jobs', 1),\n",
      "                                        cv=p.get('cv', 10),\n",
      "                                        verbose=False)\n",
      "            else:\n",
      "                estimator = LassoLarsCV()\n",
      "                \n",
      "    return estimator, scorers"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the quest ML dependencies\n",
      "\n",
      "from evaluation_measures import root_mean_squared_error, mean_absolute_error\n",
      "from sklearn.preprocessing import StandardScaler\n",
      "from sklearn.ensemble.forest import ExtraTreesClassifier\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from sklearn.linear_model.coordinate_descent import LassoCV\n",
      "from sklearn.linear_model.least_angle import LassoLarsCV, LassoLars\n",
      "from sklearn.linear_model.randomized_l1 import RandomizedLasso\n",
      "from sklearn.linear_model.randomized_l1 import RandomizedLasso\n",
      "\n",
      "from sklearn.linear_model import LinearRegression\n",
      "\n",
      "from sklearn.metrics.metrics import mean_squared_error, f1_score, \\\n",
      "    precision_score, recall_score\n",
      "from sklearn.svm.classes import SVR, SVC\n",
      "from sklearn_utils import scale_datasets, open_datasets, assert_number, \\\n",
      "    assert_string\n",
      "    \n",
      "import logging as log\n",
      "    \n",
      "# util function for scoring\n",
      "def set_scorer_functions(scorers):\n",
      "    scores = []\n",
      "    for score in scorers:\n",
      "        if score == 'mae':\n",
      "            scores.append((score, mean_absolute_error))\n",
      "        elif score == 'rmse':\n",
      "            scores.append((score, root_mean_squared_error))\n",
      "        elif score == 'mse':\n",
      "            scores.append((score, mean_squared_error))\n",
      "        elif score == 'f1_score':\n",
      "            scores.append((score, f1_score))\n",
      "        elif score == 'precision_score':\n",
      "            scores.append((score, precision_score))\n",
      "        elif score == 'recall_score':\n",
      "            scores.append((score, recall_score))\n",
      "        elif score == 'pearson_corrcoef':\n",
      "            scores.append((score, pearson_corrcoef))\n",
      "        elif score == 'binary_precision':\n",
      "            scores.append((score, binary_precision))\n",
      "            \n",
      "    return scores\n",
      "\n",
      "# sets the selection method\n",
      "#transformer = set_selection_method(config)\n",
      "\n",
      "# if the system is configured to run feature selection\n",
      "# runs it and modifies the datasets to the new dimensions\n",
      "#     if transformer is not None:\n",
      "#         log.info(\"Running feature selection %s\" % str(transformer))\n",
      "        \n",
      "#         log.debug(\"X_train dimensions before fit_transform(): %s,%s\" % X_train.shape)\n",
      "#         log.debug(\"y_train dimensions before fit_transform(): %s\" % y_train.shape)\n",
      "        \n",
      "#         X_train = transformer.fit_transform(X_train, y_train)\n",
      "        \n",
      "#         log.debug(\"Dimensions after fit_transform(): %s,%s\" % X_train.shape)\n",
      "        \n",
      "#         if X_test is not None:\n",
      "#             X_test = transformer.transform(X_test)\n",
      "\n",
      "\n",
      "# sets learning algorithm and runs it over the training data\n",
      "#estimator, scorers = set_learning_method(config, X_train, y_train)\n",
      "\n",
      "#     scores = []\n",
      "#     for score in scorers:\n",
      "#         if score == 'mae':\n",
      "#             scores.append((score, mean_absolute_error))\n",
      "#         elif score == 'rmse':\n",
      "#             scores.append((score, root_mean_squared_error))\n",
      "#         elif score == 'mse':\n",
      "#             scores.append((score, mean_squared_error))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_test = split_data(data_instances, 10)\n",
      "print(train_test['train'].shape)\n",
      "print(train_test['test'].shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(3456, 18)\n",
        "(381, 18)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:45: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Some data munging\n",
      "#X_train = scaler.fit_transform(train_test['train'][[col for col in train_test['train'].columns if col not in ['train_scores']]].values)\n",
      "#X_train = np.nan_to_num(train_test['train'][[col for col in train_test['train'].columns if col not in ['train_scores']]].values)\n",
      "print(train_test['train'].values[:10])\n",
      "X_train = train_test['train'][[col for col in train_test['train'].columns if col not in ['train_scores']]].values\n",
      "#print(X_train[:10])\n",
      "#print(type(train_test['train'][[col for col in train_test['train'].columns if col not in ['train_scores']]].values))\n",
      "X_test = np.nan_to_num(train_test['test'][[col for col in train_test['test'].columns if col not in ['train_scores']]].values)\n",
      "\n",
      "y_train = np.nan_to_num(train_test['train']['train_scores'].values)\n",
      "y_test = np.nan_to_num(train_test['test']['train_scores'].values)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[  1.20000000e+01   1.20000000e+01   3.83333330e+00  -3.98042000e+01\n",
        "   -4.11444000e+01   1.09090910e+00   1.85166670e+02   3.03059150e-02\n",
        "    0.00000000e+00   8.33333300e-01   0.00000000e+00   3.63636370e-01\n",
        "    0.00000000e+00   1.00000000e-01   8.18181800e-01   2.00000000e+00\n",
        "    4.00000000e+00   1.00000000e+00]\n",
        " [  2.40000000e+01   2.50000000e+01   3.87500000e+00  -5.50311000e+01\n",
        "   -5.30591000e+01   1.31578950e+00   1.63000000e+02   1.07399400e-02\n",
        "    0.00000000e+00   1.00000000e+00   0.00000000e+00   9.56521750e-01\n",
        "    9.09090900e-02   7.27272750e-01   1.00000000e+00   3.00000000e+00\n",
        "    2.00000000e+00   1.00000000e+00]\n",
        " [  2.00000000e+01   2.00000000e+01   4.65000000e+00  -5.95202000e+01\n",
        "   -5.09759000e+01   1.00000000e+00   2.21200000e+02   6.34206300e-02\n",
        "    0.00000000e+00   9.50000000e-01   0.00000000e+00   6.84210540e-01\n",
        "    5.55555560e-02   3.88888900e-01   1.00000000e+00   0.00000000e+00\n",
        "    2.00000000e+00   1.00000000e+00]\n",
        " [  8.00000000e+00   8.00000000e+00   4.12500000e+00  -2.64725000e+01\n",
        "   -2.61106000e+01   1.00000000e+00   1.49750000e+02   1.43631740e-01\n",
        "    0.00000000e+00   7.50000000e-01   0.00000000e+00   4.28571430e-01\n",
        "    0.00000000e+00   1.66666670e-01   1.00000000e+00   0.00000000e+00\n",
        "    0.00000000e+00   1.00000000e+00]\n",
        " [  1.50000000e+01   1.40000000e+01   3.13333340e+00  -4.83156000e+01\n",
        "   -2.98915000e+01   1.16666660e+00   2.74000000e+02   9.04076600e-02\n",
        "    0.00000000e+00   9.33333340e-01   0.00000000e+00   5.71428600e-01\n",
        "    0.00000000e+00   3.84615400e-01   1.00000000e+00   2.00000000e+00\n",
        "    0.00000000e+00   1.00000000e+00]\n",
        " [  5.00000000e+00   5.00000000e+00   2.80000000e+00  -1.67856000e+01\n",
        "   -1.48469000e+01   1.00000000e+00   2.29000000e+02   1.77685580e-02\n",
        "    0.00000000e+00   1.00000000e+00   0.00000000e+00   1.00000000e+00\n",
        "    0.00000000e+00   6.66666700e-01   1.00000000e+00   0.00000000e+00\n",
        "    0.00000000e+00   2.00000000e+00]\n",
        " [  1.70000000e+01   1.60000000e+01   4.29411750e+00  -5.13962000e+01\n",
        "   -4.38953000e+01   1.06666670e+00   1.75411760e+02   1.06787500e-01\n",
        "    0.00000000e+00   7.64705900e-01   6.25000000e-02   5.00000000e-01\n",
        "    0.00000000e+00   3.33333340e-01   8.66666700e-01   2.00000000e+00\n",
        "    2.00000000e+00   1.00000000e+00]\n",
        " [  1.50000000e+01   1.60000000e+01   3.46666670e+00  -3.86864000e+01\n",
        "   -4.30951000e+01   1.06666670e+00   1.73733340e+02   1.22860605e-02\n",
        "    0.00000000e+00   9.33333340e-01   0.00000000e+00   7.14285730e-01\n",
        "    7.69230800e-02   2.30769230e-01   9.33333340e-01   2.00000000e+00\n",
        "    2.00000000e+00   1.00000000e+00]\n",
        " [  2.60000000e+01   2.70000000e+01   3.84615370e+00  -5.98938000e+01\n",
        "   -6.81714000e+01   1.17391300e+00   6.43346100e+02   1.36657860e-01\n",
        "    3.84615400e-02   8.07692300e-01   0.00000000e+00   5.60000000e-01\n",
        "    0.00000000e+00   2.08333330e-01   9.60000000e-01   0.00000000e+00\n",
        "    3.00000000e+00   1.00000000e+00]\n",
        " [  3.00000000e+01   4.00000000e+01   4.00000000e+00  -9.71884000e+01\n",
        "   -1.26115000e+02   1.29032250e+00   1.81733340e+02   7.89426500e-02\n",
        "    3.33333350e-02   8.66666700e-01   0.00000000e+00   5.86206900e-01\n",
        "    0.00000000e+00   1.42857150e-01   9.60000000e-01   4.00000000e+00\n",
        "    6.00000000e+00   1.00000000e+00]]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# the learning and estimation function\n",
      "def train_and_estimate(X_train, X_test, y_train, y_test):\n",
      "    # TODO - try different estimators\n",
      "    estimator = SVR()\n",
      "    #estimator = SVC()\n",
      "    #estimator = LinearRegression()\n",
      "    \n",
      "    #estimator = LassoLars()\n",
      "    log.info(\"Running learning algorithm %s\" % str(estimator))\n",
      "    scorers = [('mae', mean_absolute_error), ('rmse', root_mean_squared_error)]\n",
      "    scaler = StandardScaler()\n",
      "    estimator.fit(X_train, y_train)\n",
      "    \n",
      "    if (X_test is not None) and (y_test is not None):\n",
      "        log.info(\"Predicting unseen data using the trained model...\")\n",
      "        print(\"Predicting unseen data using the trained model...\")\n",
      "        y_hat = estimator.predict(X_test)\n",
      "        log.info(\"Evaluating prediction on the test set...\")\n",
      "        for scorer_name, scorer_func in scorers:\n",
      "            v = scorer_func(y_test, y_hat)\n",
      "            log.info(\"%s = %s\" % (scorer_name, v))\n",
      "        log.info(\"Customized scores: \")\n",
      "        try:\n",
      "            log.info(\"pearson_corrcoef = %s\" % pearson_corrcoef(y_test,  y_hat))\n",
      "        except:\n",
      "            pass\n",
      "        try:\n",
      "            log.info(\"Precision score: = %s\" % precision_score(y_test, y_hat))\n",
      "        except:\n",
      "            pass\n",
      "        try:\n",
      "            log.info(\"Recall score: = %s\" % recall_score(y_test, y_hat))\n",
      "        except:\n",
      "            pass\n",
      "        try:\n",
      "            log.info(\"F1 score: = %s\" % f1_score(y_test, y_hat))\n",
      "        except:\n",
      "            pass\n",
      "        try:\n",
      "            log.info(\"MAE: = %s\" % mean_absolute_error(y_test, y_hat))\n",
      "            print(\"MAE: = %s\" % mean_absolute_error(y_test, y_hat))\n",
      "        except:\n",
      "            pass\n",
      "        try:\n",
      "            log.info(\"RMSE: = %s\" % root_mean_squared_error(y_test, y_hat))\n",
      "            print(\"RMSE: = %s\" % root_mean_squared_error(y_test, y_hat))\n",
      "        except:\n",
      "            pass\n",
      "        try:\n",
      "            res = classify_report_bin(y_test, y_hat)\n",
      "            if \"N/A\" <> res:\n",
      "                log.info(\"Classify report bin: = %s\" % res)\n",
      "            else:\n",
      "                res = classify_report_bin_regression(y_test, y_hat)\n",
      "                if \"N/A\" <> res:\n",
      "                    log.info(\"Classify report bin regression: = %s\" % res)\n",
      "                else:\n",
      "                    if ref_thd is None:\n",
      "                        log.error(\"No ref thd defined\")\n",
      "                    else:\n",
      "                        refthd = float(ref_thd)\n",
      "                        res = classify_report_regression(y_test, y_hat, refthd)\n",
      "                        log.info(\"Classify report regression: = %s\" % res)\n",
      "        except Exception, e:\n",
      "            print e\n",
      "        with open(\"predicted.csv\", 'w') as _fout:\n",
      "            for _x,  _y in zip(y_test, y_hat):\n",
      "                print >> _fout,  \"%f\\t%f\" % (_x,  _y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Tests for WMT with syntax features\n",
      "\n",
      "wmt_syntax_2999_train = '/home/chris/projects/quest-new/learning/test/79_blackbox_with_berkeley_syntax/syntaxFeatures.2999.out'\n",
      "X_test_path = '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/perceived_PE_effort/task1-1_en-es_training/en-es_score.2999.out.index'\n",
      "wmt_syntax_817_test = '/home/chris/projects/quest-new/learning/test/79_blackbox_with_berkeley_syntax/syntaxFeatures.817.out'\n",
      "y_test_path = '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/data/perceived_PE_effort/task1-1_en-es_training/en-es_score.817.out.index'\n",
      "\n",
      "#data_instances.replace(np.inf, 0.0)\n",
      "#wmt_syntax_2999 = np.nan_to_num(pd.io.parsers.read_table(wmt_syntax_2999_train).replace(str, 0.0).astype('float64', copy=True).values)\n",
      "X_train = np.nan_to_num(pd.io.parsers.read_table(wmt_syntax_2999_train).astype('float64', copy=True).values)\n",
      "#X_train = wmt_syntax_2999.loc[:, wmt_syntax_2999.dtypes == np.float64]\n",
      "X_test = np.nan_to_num(pd.io.parsers.read_table(wmt_syntax_817_test).astype('float64', copy=True).values)\n",
      "#test_strings\n",
      "\n",
      "y_train = pd.io.parsers.read_table(X_test_path).astype('float64', copy=True).values\n",
      "y_test = pd.io.parsers.read_table(y_test_path).astype('float64', copy=True).values\n",
      "#wmt_syntax_817 = np.nan_to_num(pd.io.parsers.read_table(wmt_syntax_817_test).replace(str, 0.0).astype('float64', copy=True).values)\n",
      "#y_test = pd.io.parsers.read_table(y_test).astype('float64', copy=True).values\n",
      "\n",
      "# now learn on the data\n",
      "train_and_estimate(X_train, X_test, y_train, y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Buffer has wrong number of dimensions (expected 1, got 2)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-39-0e8afda691d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# now learn on the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mtrain_and_estimate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-12-3a274e7e36d5>\u001b[0m in \u001b[0;36mtrain_and_estimate\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mscorers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'rmse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroot_mean_squared_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/svm/libsvm.so\u001b[0m in \u001b[0;36msklearn.svm.libsvm.fit (sklearn/svm/libsvm.c:1848)\u001b[1;34m()\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Buffer has wrong number of dimensions (expected 1, got 2)"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Analyzing the outputs of the quest-79-blackbox features\n",
      "# where is the IBM 1 table coming from?\n",
      "# what is GIZA being used for? \n",
      "# see features 1016-1061  - general lexical frequency features, what data are we testing against?\n",
      "\n",
      "# TODO: see the commented section in features_blackbox-79.xml - we can use many of the features here\n",
      "# Not - the comment order in the feature config XML matters!\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO - error analysis - which segs are wrong?\n",
      "# Data selection based on random indexing - this is another good paper idea\n",
      "# Domain adapation with Random indexing?\n",
      "# Ok, we need to try adapting the models to THIS DATA, and seeing if the performance improves\n",
      "\n",
      "# 19.3.14\n",
      "\n",
      "# WMT14 with the sample features downloaded from the WMT14 website\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.41200735122\n",
      "# INFO:root:rmse = 0.600616877202\n",
      "# INFO:root:Customized scores: \n",
      "# INFO:root:pearson_corrcoef = 0.404608350892 1.57542489598e-33\n",
      "\n",
      "# WMT14 with blackbox 79 from Quest - features_blackbox-79.xml\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.410457896507\n",
      "# INFO:root:rmse = 0.590381419004\n",
      "# INFO:root:Customized scores: \n",
      "# INFO:root:pearson_corrcoef = 0.475719513786 2.28212874736e-47\n",
      "# INFO:root:MAE: = 0.410457896507\n",
      "# INFO:root:RMSE: = 0.590381419004\n",
      "\n",
      "# --> quest's blackbox 79 are SLIGHTLY better\n",
      "\n",
      "# UPDATE: 23.3.14\n",
      "\n",
      "# with the features from Berkeley parser, and no zeros allowed (because it breaks the scikit learn scaling)\n",
      "#INFO:root:Evaluating prediction on the test set...\n",
      "#INFO:root:mae = 0.413500467225\n",
      "#INFO:root:rmse = 0.605250645053\n",
      "#INFO:root:Customized scores: \n",
      "#INFO:root:pearson_corrcoef = 0.379235471597 2.42423166049e-29\n",
      "#INFO:root:MAE: = 0.413500467225\n",
      "#INFO:root:RMSE: = 0.605250645053\n",
      "\n",
      "\n",
      "# OLDER ----------------------\n",
      "# UPDATE - quest isn't outputting the syntactic features, so the numbers below are INVALID\n",
      "# quest blackbox 79 with syntactic features 1101-1115\n",
      "INFO:root:Evaluating prediction on the test set...\n",
      "INFO:root:mae = 0.41070504399\n",
      "INFO:root:rmse = 0.590499036891\n",
      "INFO:root:Customized scores: \n",
      "INFO:root:pearson_corrcoef = 0.475728937252 2.27133261885e-47\n",
      "INFO:root:MAE: = 0.41070504399\n",
      "INFO:root:RMSE: = 0.590499036891\n",
      "\n",
      "# now quest blackbox 79 with syntactic features 1101-1115 WITHOUT FEATURE SELECTION\n",
      "INFO:root:Evaluating prediction on the test set...\n",
      "INFO:root:mae = 0.411954340446\n",
      "INFO:root:rmse = 0.600333605273\n",
      "INFO:root:Customized scores: \n",
      "INFO:root:pearson_corrcoef = 0.469596282711 4.81970390974e-46\n",
      "INFO:root:MAE: = 0.411954340446\n",
      "INFO:root:RMSE: = 0.600333605273\n",
      "\n",
      "# WMT14 with blackbox 79 from Quest - features_blackbox-79.xml WITHOUT FEATURE SELECTION\n",
      "\n",
      "            \n",
      "\n",
      "# now check which features are zero and why\n",
      "# zero indicies: UPDATE - they seem to be the relative differences between things like punctuation marks, \n",
      "# so it's really ok for them to be zero, although I haven't checked all of them\n",
      "\n",
      "# ---------------------------- earlier\n",
      "\n",
      "WMT14 with the baseline system from wmt12 (their implementation from github)\n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.465107739981\n",
      "RMSE: = 0.636684035633\n",
      "\n",
      "WMT14 with baseline 79 \n",
      "# Predicting unseen data using the trained model...\n",
      "MAE: = 0.492139384042\n",
      "RMSE: = 0.725983652285\n",
      "\n",
      "\n",
      "WMT12 baseline system - according to the CMU paper\n",
      "0.69 - 0.82 \n",
      "\n",
      "# WMT 2014 experiments \n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.241694973346\n",
      "RMSE: = 0.317832032721\n",
      "\n",
      "# with all 2014 en-es data - we expect scores to change because of the cross-validation    \n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.490180458094\n",
      "RMSE: = 0.677979892434    \n",
      "    \n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.501959425242\n",
      "RMSE: = 0.694692142869\n",
      "    \n",
      "    \n",
      "# WMT 2012 -- Baseline stuff\n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.828479123721\n",
      "RMSE: = 1.00643779137\n",
      "    \n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.776307444845\n",
      "RMSE: = 0.9318582504\n",
      "\n",
      "# GOT IT - with baseline 79 features file (one is commented)\n",
      "Predicting unseen data using the trained model...\n",
      "MAE: = 0.695741608119\n",
      "RMSE: = 0.838263363242\n",
      "# above was with SVR\n",
      "\n",
      "# now with LassoLars - TODO: LassoLars throws NaN error\n",
      "    \n",
      "    \n",
      "# TODO - how to check if my results are better than random?\n",
      "    \n",
      "# from  quest\n",
      "def run(config):\n",
      "    '''\n",
      "    Runs the main code of the program. Checks for mandatory parameters, opens\n",
      "    input files and performs the learning steps.\n",
      "    '''\n",
      "    # check if the mandatory parameters are set in the config file\n",
      "    x_train_path = config.get(\"x_train\", None)\n",
      "    if not x_train_path:\n",
      "        msg = \"'x_train' option not found in the configuration file. \\\n",
      "        The training dataset is mandatory.\"\n",
      "        raise Exception(msg)\n",
      "\n",
      "    y_train_path = config.get(\"y_train\", None)\n",
      "    if not y_train_path:\n",
      "        msg = \"'y_train' option not found in the configuration file. \\\n",
      "        The training dataset is mandatory.\"\n",
      "        raise Exception(msg)\n",
      "        \n",
      "    learning = config.get(\"learning\", None)\n",
      "    if not learning:\n",
      "        msg = \"'learning' option not found. At least one \\\n",
      "        learning method must be set.\"\n",
      "        raise Exception(msg)\n",
      "    \n",
      "    # checks for the optional parameters\n",
      "    x_test_path = config.get(\"x_test\", None)\n",
      "    y_test_path = config.get(\"y_test\", None)\n",
      "\n",
      "    separator = config.get(\"separator\", DEFAULT_SEP)\n",
      "    \n",
      "    labels_path = config.get(\"labels\", None)\n",
      "        \n",
      "    scale = True\n",
      "    if scale:\n",
      "        # preprocess and execute mean removal\n",
      "        X_train, X_test = scale_datasets(X_train, X_test)\n",
      "    \n",
      "    log.info(\"Opening input files ...\")\n",
      "    log.debug(\"X_train: %s\" % x_train_path)\n",
      "    log.debug(\"y_train: %s\" % y_train_path)\n",
      "    log.debug(\"X_test: %s\" % x_test_path)\n",
      "    log.debug(\"y_test_path: %s\" % y_test_path)\n",
      "\n",
      "    # open feature and response files    \n",
      "    X_train, y_train, X_test, y_test, labels = \\\n",
      "    open_datasets(x_train_path, y_train_path, x_test_path,\n",
      "                  y_test_path, separator, labels_path)\n",
      "\n",
      "   \n",
      "\n",
      "    # fits training data and predicts the test set using the trained model\n",
      "    y_hat = fit_predict(X_train, y_train, X_test, y_test, config.get(\"ref_thd\", None))\n",
      "    \n",
      "# working - modify fit predict\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# TODO: store the results in csv with some metadata about the experimental params\n",
      "# ml_directory = '/home/chris/programs/quest/learning/\n",
      "# python src/learn_model.py config/svr.yaml\n",
      "%run src/learn_model.py config/svr.cfg\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Opening input files ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Scaling datasets...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Tuning hyper-parameters for mae\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing a loss function is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''. \n",
        "  self.loss_func, self.score_func, self.scoring)\n",
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.0s finished\n",
        "INFO:root:Best parameters set found on development set:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:{'epsilon': 0.10000000000000001, 'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Tuning hyper-parameters for rmse\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "kernel ['rbf']\n",
        "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
        "Fitting 3 folds for each of 8 candidates, totalling 24 fits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing a loss function is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''. \n",
        "  self.loss_func, self.score_func, self.scoring)\n",
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.0s finished\n",
        "INFO:root:Best parameters set found on development set:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:{'epsilon': 0.10000000000000001, 'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running learning algorithm SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.01,\n",
        "  kernel=rbf, max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting unseen data using the trained model...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Evaluating prediction on the test set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:mae = 0.46500703813\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:rmse = 0.659793355871\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# output files\n",
      "training = output_dir + 'training-features.out'\n",
      "test = output_dir + 'test-features.out'\n",
      "# this cell formats and prints the training features\n",
      "with open(training,'w') as f:\n",
      "    for row in new_train:\n",
      "        print (row, file=f)\n",
      "        \n",
      "with open(test,'w') as f:\n",
      "    for row in new_test:\n",
      "        print (row, file=f)\n",
      "\n",
      "\n",
      "# TODO: try other classifiers -- get some better intuition about the performance\n",
      "# LR, NB to start\n",
      "# Neural network, etc..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "u'/home/chris/programs/quest/learning'"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run 1 with extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412518890672\n",
      "# INFO:root:rmse = 0.602574628609\n",
      "\n",
      "# run 2 WITHOUT extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412413880436\n",
      "# INFO:root:rmse = 0.602584789385\n",
      "\n",
      "# run 3 JUST extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465217126314\n",
      "# INFO:root:rmse = 0.659930041776\n",
      "\n",
      "# run 4 sanity check - random features:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465236937727\n",
      "# INFO:root:rmse = 0.659939032088\n",
      "\n",
      "# random results confirmed:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465119763497\n",
      "# INFO:root:rmse = 0.659865420079\n",
      "\n",
      "# COMING BACK - after zeroing the corpus indicies for cells which are only 1 or -1\n",
      "# finished indexing tokens...\n",
      "# similarity between vecs for: oro and gold is: 0.504181\n",
      "# similarity between vecs for: oro and covet is: 0.965443\n",
      "# before zeroing: \n",
      "# INDEX: 4798 - Source and target sentence similarity after random indexing: 0.674727\n",
      "# INDEX: 4798 - Source similarity with a random target (index 4155): 0.699771\n",
      "# after zeroing: \n",
      "# INDEX: 4798 - Source and target sentence similarity after random indexing: 0.674727\n",
      "# INDEX: 4798 - Source similarity with a random target (index 14408): 0.883923\n",
      "\n",
      "# with the new (index-zeroed) feature\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412617446921\n",
      "# INFO:root:rmse = 0.602652127017\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}