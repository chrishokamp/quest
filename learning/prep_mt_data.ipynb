{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODOS\n",
      "# - more tests and sanity checks\n",
      "# - add cross validation harness\n",
      "# - add random instance selection\n",
      "# - load serialized indices, run random indexing, and print scores into:\n",
      "# en-es.sim_scores\n",
      "\n",
      "# TODO: this doesn't work inside the ipython notebook for some reason\n",
      "# %run /home/chris/projects/random_indexing/python/wmt2014/quality_estimation/test_random_indexing.py\n",
      "\n",
      "# split that file into 10 parts (randomly) and do cross-validation"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'python' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-66-8721242b110e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# run random indexing, and print scores into:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# en-es.sim_scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpython\u001b[0m \u001b[1;33m/\u001b[0m\u001b[0mhome\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mchris\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mprojects\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mrandom_indexing\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mwmt2014\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mquality_estimation\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest_random_indexing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# split that file into 10 parts (randomly) and do cross-validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mNameError\u001b[0m: name 'python' is not defined"
       ]
      }
     ],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# sanity check: are our features any good? - compare high-scoring pairs to their QE scores\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from __future__ import print_function\n",
      "import unittest"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODOS\n",
      "# - add cross validation harness\n",
      "# - add random instance selection\n",
      "# - load serialized indices\n",
      "import re\n",
      "\n",
      "# run the indexing and serialization code here\n",
      "# Working - split the data for cross-validation\n",
      "similarity_data_path = '/home/chris/projects/random_indexing/python/wmt2014/quality_estimation/output/'\n",
      "quest_data_path = '/home/chris/programs/quest/learning/data/features/wmt2014_qe_experiments/'\n",
      "\n",
      "# semantic_scores = open(similarity_data_path + 'en-es.sim_scores', 'r').readlines()\n",
      "# print(len(semantic_scores))\n",
      "# human_scores = open(quest_data_path + 'train.effort', 'r').read().splitlines()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 84
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# open  the new features\n",
      "# rand_train = open(similarity_data_path + 'en-es.sim_scores.train', 'r').read().splitlines()\n",
      "# rand_test = open(similarity_data_path + 'en-es.sim_scores.test', 'r').read().splitlines()\n",
      "semantic_scores = open(similarity_data_path + 'en-es.sim_scores', 'r').read().splitlines()\n",
      "rand_train=semantic_scores[:3000]\n",
      "rand_test =semantic_scores[3000:]\n",
      "# open  the existing features\n",
      "# these are features learned and output by the quest framework\n",
      "quest_train = open(quest_data_path + 'train.15.en-es.tsv', 'r').read().splitlines()\n",
      "quest_test = open(quest_data_path + 'test.15.en-es.tsv', 'r').read().splitlines()\n",
      "\n",
      "train_scores = open(quest_data_path + 'train.effort', 'r').read().splitlines()\n",
      "test_scores = open(quest_data_path + 'test.effort', 'r').read().splitlines()\n",
      "\n",
      "# PREP THE TEST DATA\n",
      "new_train = [q + '\\t' + r for q,r in zip(quest_train, rand_train)]\n",
      "new_test = [q + '\\t' + r for q,r in zip(quest_test, rand_test)]\n",
      "# print (new_train[5:])\n",
      "# print (new_test[5:])\n",
      "# without the extra features - Quest file only\n",
      "# new_train = quest_train\n",
      "# new_test = quest_test\n",
      "\n",
      "# JUST the extra feature\n",
      "new_train = rand_train\n",
      "new_test = rand_test\n",
      "\n",
      "train_len = len(new_train)\n",
      "test_len = len(new_test)\n",
      "\n",
      "# sanity check - random vals between 0-1\n",
      "#new_train = [np.random.random() for l in range(train_len)]\n",
      "#new_test = [np.random.random() for l in range(test_len)]\n",
      "\n",
      "print (\"rand_train length: %i rand_test length: %i\" % (len(rand_train), len(rand_test)))\n",
      "print (\"quest_train length: %i quest_test length: %i\" % (len(quest_train), len(quest_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "rand_train length: 3000 rand_test length: 816\n",
        "quest_train length: 3000 quest_test length: 816\n"
       ]
      }
     ],
     "prompt_number": 85
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "output_dir = '/home/chris/programs/quest/learning/data/features/ems_output/'\n",
      "\n",
      "# output files\n",
      "training = output_dir + 'training-features.out'\n",
      "test = output_dir + 'test-features.out'\n",
      "# this cell formats and prints the training features\n",
      "with open(training,'w') as f:\n",
      "    for row in new_train:\n",
      "        print (row, file=f)\n",
      "        \n",
      "with open(test,'w') as f:\n",
      "    for row in new_test:\n",
      "        print (row, file=f)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# now get the results of ML with these features\n",
      "# TODO: store the results in csv with some metadata about the experimental params\n",
      "# ml_directory = '/home/chris/programs/quest/learning/\n",
      "# python src/learn_model.py config/svr.yaml\n",
      "%run src/learn_model.py config/svr.cfg\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Opening input files ...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Scaling datasets...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Tuning hyper-parameters for mae\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing a loss function is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''. \n",
        "  self.loss_func, self.score_func, self.scoring)\n",
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.0s finished\n",
        "INFO:root:Best parameters set found on development set:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:{'epsilon': 0.10000000000000001, 'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Tuning hyper-parameters for rmse\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "kernel ['rbf']\n",
        "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
        "Fitting 3 folds for each of 8 candidates, totalling 24 fits"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/home/chris/programs/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:466: DeprecationWarning: Passing a loss function is deprecated and will be removed in 0.15. Either use strings or score objects.The relevant new parameter is called ''scoring''. \n",
        "  self.loss_func, self.score_func, self.scoring)\n",
        "[Parallel(n_jobs=1)]: Done   1 jobs       | elapsed:    0.6s\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   18.0s finished\n",
        "INFO:root:Best parameters set found on development set:\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:{'epsilon': 0.10000000000000001, 'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Running learning algorithm SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma=0.01,\n",
        "  kernel=rbf, max_iter=-1, probability=False, random_state=None,\n",
        "  shrinking=True, tol=0.001, verbose=False)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Predicting unseen data using the trained model...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:Evaluating prediction on the test set...\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:mae = 0.46500703813\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "INFO:root:rmse = 0.659793355871\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# TODO: try other classifiers -- get some better intuition about the performance\n",
      "# LR, NB to start\n",
      "# Neural network, etc..."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 31,
       "text": [
        "u'/home/chris/programs/quest/learning'"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# run 1 with extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412518890672\n",
      "# INFO:root:rmse = 0.602574628609\n",
      "\n",
      "# run 2 WITHOUT extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412413880436\n",
      "# INFO:root:rmse = 0.602584789385\n",
      "\n",
      "# run 3 JUST extra feature:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465217126314\n",
      "# INFO:root:rmse = 0.659930041776\n",
      "\n",
      "# run 4 sanity check - random features:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465236937727\n",
      "# INFO:root:rmse = 0.659939032088\n",
      "\n",
      "# random results confirmed:\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.465119763497\n",
      "# INFO:root:rmse = 0.659865420079\n",
      "\n",
      "# COMING BACK - after zeroing the corpus indicies for cells which are only 1 or -1\n",
      "# finished indexing tokens...\n",
      "# similarity between vecs for: oro and gold is: 0.504181\n",
      "# similarity between vecs for: oro and covet is: 0.965443\n",
      "# before zeroing: \n",
      "# INDEX: 4798 - Source and target sentence similarity after random indexing: 0.674727\n",
      "# INDEX: 4798 - Source similarity with a random target (index 4155): 0.699771\n",
      "# after zeroing: \n",
      "# INDEX: 4798 - Source and target sentence similarity after random indexing: 0.674727\n",
      "# INDEX: 4798 - Source similarity with a random target (index 14408): 0.883923\n",
      "\n",
      "# with the new (index-zeroed) feature\n",
      "# INFO:root:Predicting unseen data using the trained model...\n",
      "# INFO:root:Evaluating prediction on the test set...\n",
      "# INFO:root:mae = 0.412617446921\n",
      "# INFO:root:rmse = 0.602652127017\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}